output.sources = src-2
output.sinks = k-2
output.channels = ch-2

# Channel
output.channels.ch-2.type = org.apache.flume.channel.kafka.KafkaChannel
output.channels.ch-2.kafka.bootstrap.servers = localhost:9092
output.channels.ch-2.kafka.topic = topic-topic
output.channels.ch-2.kafka.consumer.group.id = channel
output.channels.ch-2.parseAsFlumeEvent = true

# Sink
output.sinks.k-2.type = hdfs
output.sinks.k-2.channel = ch-2
output.sinks.k-2.hdfs.path = /user/training/flume-kafka-test/day=%Y-%m-%d
output.sinks.k-2.hdfs.rollInterval = 30
output.sinks.k-2.hdfs.rollSize = 0
output.sinks.k-2.hdfs.rollCount = 0
output.sinks.k-2.hdfs.fileType = DataStream
output.sinks.k-2.hdfs.fileSuffix = .avro
output.sinks.k-2.serializer =  org.apache.flume.sink.hdfs.AvroEventSerializer$Builder
output.sinks.k-2.serializer.compressionCodec = snappy

